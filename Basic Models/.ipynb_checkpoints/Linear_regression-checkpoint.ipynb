{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1632f9-8261-4a6a-a8e8-b1413efedfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 01:30:08.494380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761957008.546188   18409 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761957008.557688   18409 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761957008.628991   18409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761957008.629065   18409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761957008.629070   18409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761957008.629072   18409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-01 01:30:08.655897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88c52bf-e8fc-4726-a20b-b4710d205d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a3e127-11b9-45fa-a699-5acabe391332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "X = np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "              7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "Y = np.array([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "              2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "\n",
    "shap_ = X.shape\n",
    "print(shap_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2981a138-7192-4b5d-a667-fdc177ec81f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761957016.308748   18409 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Weights and bias\n",
    "weights = tf.Variable(tf.random.normal(shape=(1,), name=\"weight\"))\n",
    "bias = tf.Variable(tf.random.normal(shape=(1,), name=\"bias\"))\n",
    "\n",
    "# Linear regression\n",
    "def linear_regression(x):\n",
    "    return weights * X + bias\n",
    "\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac5f579-3365-404a-8731-c5648e222905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Process\n",
    "def run_optimization():\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = linear_regression(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    #Compute Gradients\n",
    "    gradients = g.gradient(loss, [weights, bias])\n",
    "\n",
    "    #Update W and b following gradients\n",
    "    optimizer.apply_gradients(zip(gradients, [weights, bias]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7868e486-8d78-4824-9aa9-c8bdcee78342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.60137546], dtype=float32)>\n",
      "step: 50, loss 0.913707, W:0.601375, b:-1.678615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18409/657259176.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"step: %i, loss %f, W:%f, b:%f\" % (step, loss, weights.numpy(), bias.numpy()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.59687275], dtype=float32)>\n",
      "step: 100, loss 0.895477, W:0.596873, b:-1.648761\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5927045], dtype=float32)>\n",
      "step: 150, loss 0.877687, W:0.592704, b:-1.619228\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5885891], dtype=float32)>\n",
      "step: 200, loss 0.860325, W:0.588589, b:-1.590052\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5845232], dtype=float32)>\n",
      "step: 250, loss 0.843379, W:0.584523, b:-1.561227\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.58050644], dtype=float32)>\n",
      "step: 300, loss 0.826839, W:0.580506, b:-1.532750\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5765381], dtype=float32)>\n",
      "step: 350, loss 0.810696, W:0.576538, b:-1.504616\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5726177], dtype=float32)>\n",
      "step: 400, loss 0.794941, W:0.572618, b:-1.476822\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.56874466], dtype=float32)>\n",
      "step: 450, loss 0.779563, W:0.568745, b:-1.449364\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5649183], dtype=float32)>\n",
      "step: 500, loss 0.764554, W:0.564918, b:-1.422237\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5611381], dtype=float32)>\n",
      "step: 550, loss 0.749905, W:0.561138, b:-1.395437\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5574035], dtype=float32)>\n",
      "step: 600, loss 0.735608, W:0.557404, b:-1.368960\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.553714], dtype=float32)>\n",
      "step: 650, loss 0.721653, W:0.553714, b:-1.342803\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.55006903], dtype=float32)>\n",
      "step: 700, loss 0.708033, W:0.550069, b:-1.316962\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.546468], dtype=float32)>\n",
      "step: 750, loss 0.694740, W:0.546468, b:-1.291433\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5429104], dtype=float32)>\n",
      "step: 800, loss 0.681766, W:0.542910, b:-1.266211\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5393958], dtype=float32)>\n",
      "step: 850, loss 0.669103, W:0.539396, b:-1.241293\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.53592366], dtype=float32)>\n",
      "step: 900, loss 0.656744, W:0.535924, b:-1.216678\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.53249323], dtype=float32)>\n",
      "step: 950, loss 0.644681, W:0.532493, b:-1.192358\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5291043], dtype=float32)>\n",
      "step: 1000, loss 0.632907, W:0.529104, b:-1.168332\n"
     ]
    }
   ],
   "source": [
    "# Trainig\n",
    "for step in range(1, training_steps + 1):\n",
    "    run_optimization()\n",
    "\n",
    "    if step % display_step == 0:\n",
    "        pred = linear_regression(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "        print(\"step: %i, loss %f, W:%f, b:%f\" % (step, loss, weights.numpy(), bias.numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada112f3-b029-45f9-b8cc-88d915a1efcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
